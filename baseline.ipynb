{"cells":[{"cell_type":"markdown","metadata":{"id":"eeoPd3ePetAw"},"source":["# Import"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"5g6xT0MEetA2","executionInfo":{"status":"ok","timestamp":1769051325376,"user_tz":-540,"elapsed":55244,"user":{"displayName":"손정락","userId":"10892662232752168928"}}},"outputs":[],"source":["import random\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from typing import Dict, List, Optional\n","\n","import cv2\n","import torch\n","import torch.nn.functional as F\n","from PIL import Image\n","from tqdm import tqdm\n","from transformers import ViTForImageClassification, ViTImageProcessor"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wahJBYtzsBW9","executionInfo":{"status":"ok","timestamp":1769051547939,"user_tz":-540,"elapsed":15736,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"f9f4fe8e-c31b-40e3-b03c-7be4a2ec99c5"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"Fb5ec5JVetA4"},"source":["# Settings"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Ell2IIu8etA5","executionInfo":{"status":"ok","timestamp":1769051325382,"user_tz":-540,"elapsed":2,"user":{"displayName":"손정락","userId":"10892662232752168928"}}},"outputs":[],"source":["SEED = 810\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"eqUZsZejetA6","executionInfo":{"status":"ok","timestamp":1769052555911,"user_tz":-540,"elapsed":15,"user":{"displayName":"손정락","userId":"10892662232752168928"}}},"outputs":[],"source":["MODEL_ID = \"prithivMLmods/Deep-Fake-Detector-v2-Model\"\n","\n","TEST_DIR = Path(\"/content/drive/MyDrive/1데이콘/HAI(하이)!-HectoAIChallenge:2025하반기헥토채용AI경진대회/test_data\")  # test 데이터 경로\n","\n","# Submission\n","OUTPUT_DIR = Path(\"/content/drive/MyDrive/1데이콘/HAI(하이)!-HectoAIChallenge:2025하반기헥토채용AI경진대회\")\n","OUTPUT_DIR.mkdir(parents=True, exist_ok=True)  # output 폴더 없으면 생성\n","\n","OUT_CSV = OUTPUT_DIR / \"baseline_submission.csv\""]},{"cell_type":"code","execution_count":13,"metadata":{"id":"XXXS-76setA7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769051586799,"user_tz":-540,"elapsed":17,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"f3881143-1f08-4b1c-b43a-4ef2dd740a54"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n"]}],"source":["IMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\", \".jfif\"}\n","VIDEO_EXTS = {\".mp4\", \".mov\"}\n","\n","TARGET_SIZE = (224, 224)\n","NUM_FRAMES = 10  # 비디오 샘플링 프레임 수\n","\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Device: {DEVICE}\")"]},{"cell_type":"markdown","metadata":{"id":"NhzD8BVretA8"},"source":["# Utils"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"ANXyZbiDetA8","executionInfo":{"status":"ok","timestamp":1769051588534,"user_tz":-540,"elapsed":5,"user":{"displayName":"손정락","userId":"10892662232752168928"}}},"outputs":[],"source":["def uniform_frame_indices(total_frames: int, num_frames: int) -> np.ndarray:\n","    \"\"\"비디오 프레임을 균등하게 샘플링\"\"\"\n","    if total_frames <= 0:\n","        return np.array([], dtype=int)\n","    if total_frames <= num_frames:\n","        return np.arange(total_frames, dtype=int)\n","    return np.linspace(0, total_frames - 1, num_frames, dtype=int)\n","\n","def get_full_frame_padded(pil_img: Image.Image, target_size=(224, 224)) -> Image.Image:\n","    \"\"\"전체 이미지를 비율 유지하며 정사각형 패딩 처리\"\"\"\n","    img = pil_img.convert(\"RGB\")\n","    img.thumbnail(target_size, Image.BICUBIC)\n","    new_img = Image.new(\"RGB\", target_size, (0, 0, 0))\n","    new_img.paste(img, ((target_size[0] - img.size[0]) // 2,\n","                        (target_size[1] - img.size[1]) // 2))\n","    return new_img\n","\n","def read_rgb_frames(file_path: Path, num_frames: int = NUM_FRAMES) -> List[np.ndarray]:\n","    \"\"\"이미지 또는 비디오에서 RGB 프레임 추출\"\"\"\n","    ext = file_path.suffix.lower()\n","\n","    # 이미지 파일\n","    if ext in IMAGE_EXTS:\n","        try:\n","            img = Image.open(file_path).convert(\"RGB\")\n","            return [np.array(img)]\n","        except Exception:\n","            return []\n","\n","    # 비디오 파일\n","    if ext in VIDEO_EXTS:\n","        cap = cv2.VideoCapture(str(file_path))\n","        total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","        if total <= 0:\n","            cap.release()\n","            return []\n","\n","        frame_indices = uniform_frame_indices(total, num_frames)\n","        frames = []\n","\n","        for idx in frame_indices:\n","            cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n","            ret, frame = cap.read()\n","            if not ret:\n","                continue\n","            frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n","\n","        cap.release()\n","        return frames\n","\n","    return []"]},{"cell_type":"markdown","metadata":{"id":"ZfOUYgzhetA9"},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"0juTRPRGetA-","executionInfo":{"status":"ok","timestamp":1769051589547,"user_tz":-540,"elapsed":8,"user":{"displayName":"손정락","userId":"10892662232752168928"}}},"outputs":[],"source":["class PreprocessOutput:\n","    def __init__(\n","        self,\n","        filename: str,\n","        imgs: List[Image.Image],\n","        error: Optional[str] = None\n","    ):\n","        self.filename = filename\n","        self.imgs = imgs\n","        self.error = error\n","\n","def preprocess_one(file_path: Path, num_frames: int = NUM_FRAMES) -> PreprocessOutput:\n","    \"\"\"\n","    파일 하나에 대한 전처리 수행\n","\n","    Args:\n","        file_path: 처리할 파일 경로\n","        num_frames: 비디오에서 추출할 프레임 수\n","\n","    Returns:\n","        PreprocessOutput 객체\n","    \"\"\"\n","    try:\n","        frames = read_rgb_frames(file_path, num_frames=num_frames)\n","\n","        imgs: List[Image.Image] = []\n","\n","        for rgb in frames:\n","            imgs.append(get_full_frame_padded(Image.fromarray(rgb), TARGET_SIZE))\n","\n","        return PreprocessOutput(file_path.name, imgs, None)\n","\n","    except Exception as e:\n","        return PreprocessOutput(file_path.name, [], str(e))"]},{"cell_type":"markdown","metadata":{"id":"dk0z0bUOetA-"},"source":["# Model Load"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"7UJLTw-MetA_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769051591041,"user_tz":-540,"elapsed":629,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"a0a620c0-a6ae-4a19-ff43-3a43bd4c65b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading model...\n","Model loaded: prithivMLmods/Deep-Fake-Detector-v2-Model\n","Model config: num_labels=2\n","id2label: {0: 'Realism', 1: 'Deepfake'}\n"]}],"source":["print(\"Loading model...\")\n","model = ViTForImageClassification.from_pretrained(MODEL_ID).to(DEVICE)\n","processor = ViTImageProcessor.from_pretrained(MODEL_ID)\n","model.eval()\n","\n","print(f\"Model loaded: {MODEL_ID}\")\n","print(f\"Model config: num_labels={model.config.num_labels}\")\n","if hasattr(model.config, 'id2label'):\n","    print(f\"id2label: {model.config.id2label}\")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"lGE9b-lbetA_","executionInfo":{"status":"ok","timestamp":1769051593047,"user_tz":-540,"elapsed":8,"user":{"displayName":"손정락","userId":"10892662232752168928"}}},"outputs":[],"source":["def infer_fake_probs(pil_images: List[Image.Image]) -> List[float]:\n","    if not pil_images:\n","        return []\n","\n","    probs: List[float] = []\n","\n","    with torch.inference_mode():\n","        inputs = processor(images=pil_images, return_tensors=\"pt\")\n","        inputs = {k: v.to(DEVICE, non_blocking=True) for k, v in inputs.items()}\n","        logits = model(**inputs).logits\n","        batch_probs = F.softmax(logits, dim=1)[:, 1]\n","        probs.extend(batch_probs.cpu().tolist())\n","\n","    return probs"]},{"cell_type":"markdown","metadata":{"id":"SRw5VI0vetA_"},"source":["# Inference"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"UPTobvJFetBA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769052419354,"user_tz":-540,"elapsed":825309,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"77834376-1510-4a57-92f8-b96d60afe83c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test data length: 500\n"]},{"output_type":"stream","name":"stderr","text":["Processing: 100%|██████████| 500/500 [13:45<00:00,  1.65s/it]"]},{"output_type":"stream","name":"stdout","text":["Inference completed. Processed: 500 files\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["files = sorted([p for p in TEST_DIR.iterdir() if p.is_file()])\n","print(f\"Test data length: {len(files)}\")\n","\n","results: Dict[str, float] = {}\n","\n","# 전처리 및 추론\n","for file_path in tqdm(files, desc=\"Processing\"):\n","    out = preprocess_one(file_path)\n","\n","    # 1. 에러 로깅\n","    if out.error:\n","        print(f\"[WARN] {out.filename}: {out.error}\")\n","\n","    # 2. 정상 추론\n","    elif out.imgs:\n","        probs = infer_fake_probs(out.imgs)\n","        results[out.filename] = float(np.mean(probs)) if probs else 0.0\n","\n","    # 3. 둘 다 없으면 0.0 (real)\n","    else:\n","        results[out.filename] = 0.0\n","\n","print(f\"Inference completed. Processed: {len(results)} files\")"]},{"cell_type":"markdown","metadata":{"id":"H1ck4repetBA"},"source":["# Submission"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"i4pQtMhSetBA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769052491792,"user_tz":-540,"elapsed":498,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"e9679bd6-3f03-4a84-bcf5-d828249e979e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Saved submission to: /content/drive/MyDrive/1데이콘/HAI(하이)!-HectoAIChallenge:2025하반기헥토채용AI경진대회/output/baseline_submission.csv\n"]}],"source":["submission = pd.read_csv('/content/drive/MyDrive/1데이콘/HAI(하이)!-HectoAIChallenge:2025하반기헥토채용AI경진대회/sample_submission.csv')\n","submission['prob'] = submission['filename'].map(results).fillna(0.0)\n","\n","# CSV 저장\n","submission.to_csv(OUT_CSV, encoding='utf-8-sig', index=False)\n","print(f\"Saved submission to: {OUT_CSV}\")"]},{"cell_type":"code","source":[],"metadata":{"id":"G7yezfVArWLQ"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}